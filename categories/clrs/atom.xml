<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: clrs | Chouqin & Laoqi]]></title>
  <link href="/categories/clrs/atom.xml" rel="self"/>
  <link href="/"/>
  <updated>2012-12-13T14:26:37+08:00</updated>
  <id>/</id>
  <author>
    <name><![CDATA[weiboatchouqingithubchouqinnameQiping Liemailliqiping1991@gmail.com]]></name>
    
  </author>
  <generator uri="https://github.com/recurser/jekyll-plugins">Recurser</generator>

  
  <entry>
    <title type="html"><![CDATA[红黑树扩充与动态规划]]></title>
    <link href="/clrs/2012/12/12/clrs-14-15"/>
    <updated>2012-12-12T00:00:00+08:00</updated>
    <id>/clrs/2012/12/12/clrs-14-15</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p></p>

<h2 id="section">红黑树的扩充</h2>

<p>由于红黑树这种结构很好的平衡性（树的高度不会很高），
对于动态变化的集合插入，查找，删除等操作的复杂度都比较低，
通过给它的节点增加一些其他的属性，
能够得到一些在特定情况下很有用的数据结构。</p>

<h3 id="section-1">扩充数据结构的四个步骤</h3>

<ol>
  <li>选择基础的数据结构</li>
  <li>确定需要给数据结构添加哪些信息，
这些信息可能被添加到每个节点中，也可能被添加作为整体数据结构的性质</li>
  <li>验证在数据结构的基本操作的过程中，这些信息可以被有效的维护，
这里的有效是指不会因为维护这些信息增加基础操作的复杂度</li>
  <li>利用这些信息提供一些有用的操作</li>
</ol>

<h3 id="section-2">通过扩充红黑树得到顺序统计</h3>

<p>通过给红黑树的每一个节点x附加属性size[x]，
表示以x为根的子树的节点个数，
可以通过递归确定一棵红黑树的第i小关键字的元素。
由于包含n个元素的红黑树的高度为<script type="math/tex"> O(\lg n) </script>，每次递归高度都会下降一层，
所以查找第i小关键字的时间复杂度为<script type="math/tex"> O(\lg n) </script>。</p>

<p>在第9章中，给出了获取n个元素的数组中第i个元素的<script type="math/tex"> \Theta(n) </script>的算法，
而一个包含n个元素的数组如果是有序的话，那么获取第i个元素的复杂度是<script type="math/tex"> O(1) </script>。
但是这种扩充的数据结构的好处在于它的动态性，它的插入和删除的时间复杂度也是<script type="math/tex"> O(\lg n) </script>，
而一个有序数组的插入和删除的复杂度是<script type="math/tex"> O(n) </script>。</p>

<h3 id="section-3">通过扩充红黑树得到区间树</h3>

<p>在区间树中，每一个节点x包含了一段区间int[x]，同时包含了一个max[x]，
表示以x为根的子树中所有区间的右端点的最大值，同时每一个节点的key[x] = low[int[x]]，
也就是说是把每一个节点所包含区间的左端点作为key。</p>

<p>区间树使得查找整个红黑树中与某一个区间i重合的区间变得十分容易，
可以如下递归实现：</p>

<ol>
  <li>如果当前节点为空，返回空节点</li>
  <li>如果区间i与当前节点的区间重合，返回当前节点</li>
  <li>如果区间i的左端点小于当前节点左儿子的max，递归查找左子树</li>
  <li>否则递归查找右子树</li>
</ol>

<p>情况1，2很自然，情况4也比较好理解，
因为如果i的左端点大于左儿子的max，它就大于那么对于左子树中所有节点的右端点，
左子树中一定不存在和区间i重合区间。情况3需要一定的思考，
因为如果i的左端点小于当前节点左儿子的max，并不能保证它一定不会与右子树中的区间重合，
所以如果只是递归查找左子树，如果左子树中有区间和i重合，那么能够返回正确结果
（因为只需要找到一个和i重合的区间就可以），如果左子树中没有区间与i重合，
那右子树中可能会有区间与i重合，导致没有返回正确的结果。情况是这样的吗？</p>

<p>不是这样的，下面可以证明在情况3时如果左子树中没有找到与i重合的区间，
那么在右子树中也一定不存在和i重合的区间。</p>

<p>假设左儿子的max来自于high[j]（也就是说，是左子树中区间j的右端点)，
那么一定有</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
high[i] < low[j]
 %]]&gt;</script>

<p>否则区间i和j重合，对于右子树中的任意区间k，一定有</p>

<script type="math/tex; mode=display"> 
low[k] \geq low[j] > high[i] \text{第一个不等式成立是根据红黑树关键字的性质}
</script>

<p>所以k与i不重合。</p>

<h2 id="section-4">动态规划</h2>

<p>动态规划主要用于求解最优化问题，
它的基本思想是通过把子问题的结果保存起来，
这样当遇到一个更大的问题时，如果它需要解决子问题，
那么可以直接使用保存好的子问题的结果，而不用再去重复解决子问题。</p>

<h3 id="section-5">动态规划适用的基本条件</h3>

<p>使用动态规划必须要满足两个基本的条件：</p>

<ol>
  <li>最优子结构。一个问题的最优解包含子问题的最优解。
通常可以通过&#8221;剪切-粘贴&#8221;的方法证明最优子结构，也就是说，
假设一个问题的最优解没有包含子问题的最优解，
那么把相应的子问题的解替换成最优解将得到一个更好的解，
从而得出矛盾。</li>
  <li>重叠子问题。如果没有大量的重叠子问题，
那么直接通过递归求解子问题就可以，
动态规划相对于递归的好处也就在于不用重复去计算重叠的子问题，
从而节省了时间。</li>
</ol>

<h3 id="section-6">动态规划解题的基本思路</h3>

<p>在确定了一个问题适合采用动态规划进行解决之后，
仍然需要考虑几个问题。最主要的问题就是如何将问题利用更小的子问题来进行解决，
此时的思路是通过把原来的问题通过转化变成更小的子问题，
利用合适的转化可以把一个问题缩小成一个更小的子问题，比如最长递增子序列问题，
求以元素n结尾的最长递增子序列的长度，
可以转化为求以比n小的排在n前面的某个元素结尾的最长递增子序列的长度。
通过转化之后问题就缩小了。</p>

<p>将问题转换成子问题之后，必须要知道如何通过子问题的解得到原问题的解，
也就是所谓的递推公式，
比如上述问题，知道n之前的某个小于n元素的最长子序列的长度之后，
n的最长子序列的长度就是这个长度加1。</p>

<p>一个问题可能转化成多个子问题，比如说上面的问题，
比n小的排在n之前的元素可能有多个，这时，就需要从多个子问题之间做出选择。
这个选择通常是比较容易的，直接从所有根据子问题递推得到的解中选出一个最优解即可。
一般情况下，还需要记录此时的选择，用于构造出一个最优解。</p>

<p>把上述的问题都考虑好之后，就可以按照问题的大小，
从小到大依次将各个问题解决，直到达到所需要的问题的大小，
就得到了所需问题的解。</p>

<h3 id="section-7">动态规划的经典问题</h3>

<h4 id="lcs">最长公共子序列（LCS）</h4>

<ul>
  <li>问题描述：
定义序列<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>的一个子序列为
<script type="math/tex">% &lt;![CDATA[
 Z = <x_{i_1}, x_{i_2}, ..., x_{i_k}>  %]]&gt;</script>，其中
<script type="math/tex">% &lt;![CDATA[
 i_1 < i_2 < ... < i_k, k \geq 1  %]]&gt;</script>。求两个序列
<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>和<script type="math/tex">% &lt;![CDATA[
 Y = <y_1, y_2, ..., y_n>  %]]&gt;</script>的最长公共子序列的长度c[m, n]。</li>
  <li>
    <p>求解方法：
定义c[i, j]为序列<script type="math/tex"> X_i </script>和<script type="math/tex"> Y_j </script>的LCS的长度，
有如下递推公式成立</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
      c[i, j] = 
          \begin{cases}
              0 & \text{i=0 或j=0} \\
              c[i-1, j-1] + 1 & i,j > 0, x_i = y_j \\
              max\{c[i, j-1], c[i-1, j]\} & i,j > 0, x_i \neq y_j
          \end{cases}
   %]]&gt;</script>
  </li>
  <li>说明:
其实c[i, j]有三个子问题， c[i-1, j-1], c[i-1, j], c[i, j-1],
为什么当<script type="math/tex"> x_i = y_j </script>时只需要考虑第一个子问题，因为有如下不等式成立:</li>
</ul>

<script type="math/tex; mode=display">
c[i-1, j-1] + 1 \geq c[i, j-1] \\
c[i-1, j-1] + 1 \geq c[i-1, j]
</script>

<p>因为c[i, j-1]相对于c[i-1, j-1]就多了一个元素c[i]，
最多能够为最长公共子序列多增加长度1，同理对于c[i-1, j]也是如此。</p>

<h4 id="section-8">背包问题</h4>

<ul>
  <li>问题描述：
给定一个重量为w的背包，有n件商品重量分别为<script type="math/tex"> w_1, w_2, ..., w_n </script>,
价值分别为<script type="math/tex"> v_1, v_2, ..., v_n </script>，求这个背包能容纳的最大的商品价值</li>
  <li>
    <p>问题求解：</p>

    <ul>
      <li>如果对于每一件商品，可以拿取任意多次，则定义K(w)表示重量为w的背包最大的价值，
  有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w) = max\{K(w-w_i) + v_i\}, i=1..n, w_i < w
   %]]&gt;</script>

    <ul>
      <li>如果没一件商品只能拿一次，就不能采取上面的方法了，因为如果在K(w)转换至<script type="math/tex"> K(w-w_i) </script>时使用了
  商品i, 在求解<script type="math/tex"> K(w-w_i) </script>就不能再使用商品i,上述的递推公式不成立。必须采用另外一种方法。
  定义K(w, i)为重量为w的背包在装载商品1..i时的最大价值，有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w, i) = max\{K(w-w_i, i-1) + v_i, K(w, i-1)\}, i=1..n, w_i < w
   %]]&gt;</script>
  </li>
</ul>

<h3 id="floyd">Floyd算法的正确性</h3>

<p>Floyd算法用于求解图中所有节点中的最短路径。
基本思想是通过n（n为节点个数）次循环更新所有节点对之间的最短路径，
伪代码如下：</p>

<p><div class="highlight"><pre><code class="pascal">    <span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
        <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
            <span class="k">for</span> <span class="n">j</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
                <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="err">&amp;</span><span class="n">lt</span><span class="o">;</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">then</span>
                    <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">:=</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">+</span><span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">;</span>
</code></pre>
</div>
</p>

<p>在每次迭代时，对于任意节点对(i, j)，如果(i, k)的路径长度加(k, j)的路径长度小于
原来的(i, j)的路径长度，
那么就将(i, j)的路径长度更新为(i, k)的路径长度加(k, j)的路径长度（也就是说，
让(i, j)的最短路径经过k）。
算法的时间复杂度为<script type="math/tex"> O(n^3) </script>。</p>

<p>动态规划对于这个算法的理解是，在迭代k结束之后，
此时(i, j)的最短路径为仅使用{1, 2, &#8230;, k}作为中间节点的最短路径，
当循环结束时，k=n, 此时(i, j)的最短路径为使用任意节点作为中间节点的最短路径，
也就是(i, j)之间的最短路径。</p>

<p>凭直接感觉，比如说(i, j)之间的最短路径为：</p>

<script type="math/tex; mode=display">
i \rightarrow ... \rightarrow k_1 \rightarrow ... \rightarrow k_2 \rightarrow ... \rightarrow j
</script>

<p>其中<script type="math/tex">% &lt;![CDATA[
 k_1 < k_2  %]]&gt;</script>,
如果最外层的循环遍历到<script type="math/tex"> k_1 </script>时，因为此时不能使用<script type="math/tex"> k_2 </script>作为中间节点，
所以不会把(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>，
当允许使用<script type="math/tex"> k_2 </script>作为中间节点时，
有不会再去遍历<script type="math/tex"> k_1 </script>让(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>, 
所以，(i, j)之间的最短路径没有被找到，这个算法好像是错误的。</p>

<p>我开始老是纠结在这样的感觉中，
认为Floyd算法可能并没有找到一条最短的路径，
可是又总是找不到一个反例，
后面经过仔细地思考，总结出两种方法来说明这个算法的正确性，
解除了我的疑虑。</p>

<h4 id="floyd-1">通过循环不变式来证明Floyd算法的正确性</h4>

<p>通过证明以下循环不变式证明算法的正确性:</p>

<p>在第k轮迭代开始前，对于任意节点对(i, j)，
此时的最短路径长度为使用节点{1, 2, .., k-1}作为中间节点的最短路径长度。</p>

<ol>
  <li>初始化：在开始时，k=1, 此时的最短的路径为不使用任何中间节点的最短路径。</li>
  <li>保持：在第k轮迭代开始时，
此时(i, j)之间的最短路径为使用{1，2，&#8230;, k-1}作为中间节点的最短路径，
令p为(i, j)之间使用{1, 2, &#8230;, k}的最短路径：
    <ul>
      <li>如果path[i][k] + path[k][j] &lt; path[i][j]，
 那么此时p一定为<script type="math/tex"> i \xrightarrow{p_1} k \xrightarrow{p_2} j </script>，
 其中<script type="math/tex"> p_1 </script>为(i, k)之间使用{1, 2, &#8230;, k-1}作为中间节点的最短路径，
 <script type="math/tex"> p_2 </script>为(k, j)之间使用{1, 2, &#8230;, k-1}作为中间节点的最短路径。
 所以此时p的长度为path[i][k] + path[k][j]，不变式得以保持</li>
      <li>如果path[i][k] + path[k][j] &gt;= path[i][j]，
 那么此时p一定也是(i, j)仅经过{1, 2, &#8230;, k-1}的最短路径(也就是说，
 此时p一定不经过k)，p的长度就是path[i][j], 不变式同样可以保持</li>
    </ul>
  </li>
  <li>终止：循环结束时，k=n+1, 此时(i, j)的最短路径是使用任意节点作为中间节点的最短路径，
也就是(i, j)的最短路径。</li>
</ol>

<p>对于这个循环不变式，定义<script type="math/tex"> path^{(k)}(i, j) </script>表示(i, j)之间仅使用节点1,&#8230;,k作为中间节点的最短路径的长度，
利用这个递推公式：</p>

<script type="math/tex; mode=display">
path^{(k)}(i, j) = min\{ path^{(k-1)}(i, k) + path^{(k-1)}(k, j), path^{(k-1)}(i, j) \}
</script>

<p>可能要更好理解一些。</p>

<h4 id="floyd-2">通过归纳证明Floyd算法的正确性</h4>

<p>可以通过这样一种思路来证明：假设k是(i, j)最短路径中最大的中间节点，
也就是说对于(i, j)最短路径中任意的中间节点m, 有<script type="math/tex"> m \leq k </script>，这样，
k是(i, j)最短路径中最后被迭代的节点，如果在迭代到k时，
能够将(i, j)之间最短路径长度正确的设置，那么这个算法就是正确的。
在迭代k时，如果(i, k)和(k, j)之间的最短路径已经被正确设置时，
那么(i, j)在迭代k结束之后能够被正确设置。</p>

<p>下面通过归纳(i, j)路径中中间节点的个数n来证明在迭代k(k是(i, j)最短路径中最后被迭代的节点)时，
(i, k)和(k, j)最短路径已经被正确的设置：</p>

<ol>
  <li>当n=1, 在迭代k时，(i, k)和(k, j)都没有中间节点，
最短路径就是节点i和k以及k和j之间的距离, 已经被正确的设置。</li>
  <li>如果<script type="math/tex"> n \leq s </script>时，命题成立。那么当n=s+1时，在迭代k时，
对于路径(i, k), 它的中间节点的个数<script type="math/tex"> n_1 \leq s </script>，
那么当这条路径的最后一个节点<script type="math/tex"> k_1 </script>被迭代时，<script type="math/tex"> (i, k_1) </script>和<script type="math/tex"> (k_1, k) </script>已经被正确设置，
迭代之后，能够将路径(i, k)正确设置，同理可以证明路径(k , j)也能够被正确设置。</li>
  <li>由上述两步可以得知对于任意个数的中间节点，(i, j)在迭代最后一个节点k时，
(i, k)和(k, j)能够被正确的设置。</li>
</ol>

<h3 id="section-9">忽略我</h3>
<p>最后还是吐槽一下动态规划这一章的翻译真的很烂，
感觉和前面的章节不是同一个人翻译的，
很多语句很不通顺，比如说有个反问句就绕了我好久，
试着推测原文才明白什么意思。
人和人之间还是有差距的啊，不管做什么都是，
希望后面的几章能够翻译好一点，bless!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《算法导论》之基本数据结构]]></title>
    <link href="/clrs/2012/12/04/clrs-10-13"/>
    <updated>2012-12-04T00:00:00+08:00</updated>
    <id>/clrs/2012/12/04/clrs-10-13</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p></p>

<h2 id="section">散列表中碰撞的解决</h2>
<p>由于散列表的元素个数小于关键字的取值集合U,
因此会有两个不同的关键字映射到散列表的同一个槽上，
这时就发生了碰撞。发生了碰撞时，
书上给出了两种方法来解决，
而且保证此时的散列表平均情况下的查找复杂度是O(1)。</p>

<h3 id="section-1">链接法</h3>
<p>在链接法中，关键字映射到同一个槽上的元素通过一个链表来保存，
此时散列表T[0..m-1]的任意元素T[j]是一个链表，
当插入一个元素时，将元素放在它所对应的槽所指向链表的头部。
下面对链接法的性能进行分析。</p>

<p>定义散列表T的装载因子<script type="math/tex"> \alpha = n / m </script>, 其中n是元素个数，m是散列表槽数,
我们假设元素满足简单一致散列的条件：
任何元素散列到m个槽中的每一个的可能性是相同的。</p>

<p>用<script type="math/tex"> n_j </script>表示链表T[j]的长度，有
$$
E[n_j] = \alpha = n/m
$$</p>

<p>有如下性质成立：</p>

<ol>
  <li>
    <p>链接方式散列表在简单一致假设下，查找一个不存在元素所需时间的期望为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>假设查找的元素是k, 它所对应的槽为h(k)，链表T[h(k)]的长度<script type="math/tex"> E[n_{h(k)}] = \alpha </script>，
 所以平均情况下需要遍历一个长度为<script type="math/tex"> \alpha </script>的链表，外加常数的散列函数时间和寻址T[h(k)]的时间，
 总共为<script type="math/tex"> \Theta (1 + \alpha) </script></p>
  </li>
  <li>
    <p>链接方式散列表在简单一致假设下，平均查找一个已存在的元素所需的时间为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>对于任意元素x，检查的元素个数等于x所在链表中，出现在x之前的元素个数加1。
 设<script type="math/tex"> x_i </script>是第i个插入的元素，i=1,2,..,n,
 定义：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

     X_{ij} =
      \begin{cases}
          1 & x_i\text{和}x_j\text{在同一槽中} \\
          0 & \text{否则}
      \end{cases}
  %]]&gt;</script>

    <p>由简单一致性假设，<script type="math/tex"> E[X_{ij}] = 1/m </script>，所以检查元素个数的期望为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 \begin{array} {lcl}
 E[\frac{1}{n} \sum_{i=1}^{n} (1 + \sum_{j=0}^{i-1}X_{ij})]
     &=& 1 + \frac{n-1}{2m} \\
     &=& 1 + \frac{\alpha}{2} - \frac{\alpha}{2n}
 \end{array}
  %]]&gt;</script>

    <p>所以平均查找时间为: <script type="math/tex"> \Theta (2 + \frac{\alpha}{2} - \frac{\alpha}{2n}) = \Theta (1 + \alpha) </script></p>
  </li>
</ol>

<!--more-->

<h3 id="section-2">开放寻址法</h3>
<p>在开放寻址法中，对于每一个关键字k，定义探查序列
    &lt;h(k, 0), h(k, 1),&#8230;, h(k, m-1)&gt;
是&lt;0, 1, &#8230;, m-1&gt;的一个排列。在插入某一个元素x时，如果它的关键字是k,
按照它所对应的探查序列从h(k, 0)到h(k, m-1)依次检查散列表，如果h(k,i)是空槽，
那么将x插入到这个槽，否则检查h(k, i+1)。在查找时，
也是沿着探查序列开始寻找。</p>

<p>探查序列的计算方法有很多，比如说线性探查法，二次探查法，双重散列法。
但是这些技术都不能保证一致散列的假设：
对于每一个关键字k, &lt;h(k, 0), h(k, 1),&#8230;, h(k, m-1)&gt;是&lt;0, 1, &#8230;, m-1&gt;的任何一种排列的可能性是相同的。</p>

<p>在一致散列的假设下，有如下性质成立：</p>

<ol>
  <li>
    <p>对于装载因子为<script type="math/tex">% &lt;![CDATA[
 \alpha = n/m < 1  %]]&gt;</script>的开放散列表，查找一个不存在的元素所需的探查数期望至多为<script type="math/tex"> \frac{1}{1-\alpha} </script></p>

    <p>定义随机变量X为探查数，<script type="math/tex"> A_i </script>为进行了第i次探查，有:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 \begin{array} {lcl}
     E[X] &=& \sum_{i=1}^{\infty} i \bullet Pr\{X = i\} \\
            &=& (Pr\{X=1\} + Pr\{X=2\} + ...) + (Pr\{X=2\} + Pr\{X=3\} + ...) + ... \\
            &=& \sum_{i=1}^{\infty}Pr\{ X \geq i \} \\
     Pr\{ X \geq i \} &=& Pr\{ A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-1} \} \\
         &=& Pr\{A_1\} \bullet Pr\{ A_2 | A_1 \} \bullet ... \bullet Pr\{ A_{i-1} | A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-2} \} \\
     Pr\{ A_1 \} &=& \frac{n}{m} = \alpha \\
     Pr\{ A_j | A_1 \bigcap A_2 \bigcap ... \bigcap A_{j-1} \} &=& \frac{n-j+1}{m-j+1} \leq \frac{n}{m} = \alpha \\
     Pr\{X \geq i \} &=& \frac{n}{m} \bullet \frac{n-1}{m-1} \bullet \frac{n-2}{m-2} \bullet ... \bullet \frac{n-i+2}{m-i+2}
         \leq (\frac{n}{m})^{i-1} = \alpha^{i-1} \\
     E[X] &=& \sum_{i=1}^{\infty}Pr\{ X \geq i \} \leq \sum_{i=1}^{\infty} \alpha^{i-1}
         = \sum_{i=1}^{\infty} \alpha^{i-1} = \frac{1}{1-\alpha}
 \end{array}
  %]]&gt;</script>
  </li>
  <li>
    <p>向一个装载因子为<script type="math/tex"> \alpha </script>的开放寻址散列表中插入一个元素，平均情况下最多进行<script type="math/tex"> \frac{1}{1-\alpha} </script>次探查。</p>

    <p>因为要插入一个元素x，只需要做一次查找x就能找到一个空槽，所以探查次数与查找一个不存在元素的查找相同。</p>
  </li>
  <li>
    <p>一个装载因子为<script type="math/tex"> \alpha </script>的开放散列表中查找一个存在的元素的期望探查次数至多为<script type="math/tex"> \frac{1}{\alpha} \ln \frac{1}{1-\alpha} </script></p>

    <p>对于每一个元素x，查找它所需要的探查次数与插入它所需要的探查次数相同，
 对于第i个插入的元素x, 所需的探查次数最多为<script type="math/tex"> \frac{1}{1-\frac{i}{m}} = \frac{m}{m-i} </script>，
 所以平均的探查次数最多为：</p>

<script type="math/tex; mode=display">
 \frac{1}{n} \sum_{i=0}^{n-1} \frac{m}{m-i} = \frac{m}{n} \sum_{i=0}^{n-1}\frac{1}{m-i}
     \leq \frac{1}{\alpha} \ln \frac{1}{1-\alpha}
 </script>
  </li>
</ol>

<p>对比开放寻址法与链接法，链接法能够支持装载因子<script type="math/tex"> \alpha > 1 </script>的情况，
而开放寻址法不能支持。</p>

<h2 id="section-3">二叉查找树与红黑树</h2>
<p>二叉查找树和红黑数都是用来存储动态集合的数据结构，
红黑树对二叉查找树进行了扩展，通过一些额外的性质，
保证了二叉查找树的平衡性，
这样就能够保证树的高度为O(lgn)， 其中n是节点的个数。
有了这些额外的性质时，
在插入节点或者删除节点的时候就需要一些额外的操作来保持这些性质。</p>

<h3 id="section-4">二叉查找树的基本操作</h3>
<p>二叉查找树所支持的基本操作有：</p>

<ol>
  <li>查找。
因为在二叉查找树中， 对于任何一个节点，
左子树中的关键字都小于当前节点的关键字，
而右子树中的关键字都大于当前节点的关键字，
所以可以通过一个简单的递归的来查找一个关键字：
如果关键字大于当前关键字，则递归查询右子树，
否则如果关键字小于当前关键字，递归查询左子树。</li>
  <li>
    <p>插入。插入也可以通过简单的递归来实现：</p>

    <ul>
      <li>如果要插入的关键字大于当前的关键字，如果右子树为空，
 则把这个节点作为当前节点的右儿子，否则递归插入到右子树</li>
      <li>如果要插入的关键字小于当前的关键字，如果左子树为空，
 则把这个节点作为当前节点的左儿子，否则递归插入到左子树</li>
    </ul>
  </li>
  <li>寻找二叉查找树中的最小节点和最大节点。
这两个操作是对称的，只需要给出求最小节点的方法，
采用递归的方式实现：
    <ul>
      <li>如果左子树非空，则返回左子树中的最小节点</li>
      <li>否则返回当前节点</li>
    </ul>
  </li>
  <li>寻找节点x的直接前趋或者直接后继。
这两个操作是对称的，只需要给出寻找直接后继的方法：
节点x的直接后继是指关键字大于key[x]中最小的那个节点，
    <ul>
      <li>如果x的右儿子存在，那么后继在x的右子树中，
 以x的右子树中的最小节点就是x的直接后继</li>
      <li>如果x的右儿子不存在，那么需要</li>
    </ul>
  </li>
  <li>删除。在删除一个节点x的时候，有三种情况需要考虑：
    <ul>
      <li>如果要删除的节点是叶节点，直接删除即可。</li>
      <li>如果要删除的节点只有一个儿子，那么先建立它的祖先和它儿子的父子关系,
 然后把它删除。</li>
      <li>如果要删除的节点有两个儿子，那么先从它的右子树中找到x的直接后继节点y，
 此时y一定没有左儿子（因为如果y有左儿子的话左儿子一定大于x且小于y，
 与y是x的直接后继矛盾）, 所以可以把y先从树中移除(删除y一定属于前两种情况)，
 然后用y代替x的位置。</li>
    </ul>
  </li>
</ol>

<h3 id="section-5">红黑树的性质</h3>
<p>相对于二叉查找树来说，赋予了每一个节点红色或者黑色，
同时整个红黑树需要保持下面的性质：</p>

<ol>
  <li>每个节点或者是红的，或者是黑的</li>
  <li>根节点是黑的</li>
  <li>每个叶节点是黑的</li>
  <li>如果一个节点是红的，那么它的两个儿子必须是黑的</li>
  <li>对每一个节点，从该节点到叶节点的所有路径上包含相同数目的黑节点</li>
</ol>

<p>其中，性质3可以不用考虑，因为在红黑树中，
所有的叶节点都是NIL, 它永远都是黑色。</p>

<p>有了这几条性质之后，
能保证一棵有n个节点（不包括NIL叶节点）的红黑树高度至多为2lg(n+1)。
这时，查找操作能够在O(lgn)的时间内完成。</p>

<h3 id="section-6">在插入和删除时红黑树性质的保持</h3>
<p>红黑树的性质可能在插入或者删除节点的时候被破坏，
此时需要一些操作来维护红黑数的性质。</p>

<h4 id="section-7">插入</h4>
<p>插入一个节点时，始终把新插入的节点的设成红色，
这时，会有两种原因造成红黑树性质的破坏：</p>

<ol>
  <li>如果新插入的节点是根节点，那么会破坏性质2</li>
  <li>如果插入节点的父节点是红色，那么将会破坏性质4</li>
</ol>

<p>函数RB-INSERT_FIX_UP()用于在插入z时红黑树T性质的保持：</p>

<pre><code>def RB-INSERT-FIXUP (T, z):
    while color[p[z]] = RED
        do if p[z] = left[p[p[z]]]
            then y ← right[p[p[z]]]
            if color[y] = RED                   
                then color[p[z]] ← BLACK        ###case1
                color[y] ← BLACK                ###case1
                color[p[p[z]]] ← RED            ###case1
                z ← p[p[z]]                     ###case1
            else if z = right[p[z]]            
                    then z ← p[z]               ###case2
                    LEFT-ROTATE (T, z)          ###case2
                color[p[z]] ← BLACK             ###case3
                color[p[ p[z]]] ← RED           ###case3
                RIGHT-ROTATE (T, p[p[z]])       ###case3
        else (same as then clause
            with “right” and “left” exchanged)
    color[root[T]] ← BLACK
</code></pre>

<p>这个函数能达到目的因为：</p>

<ol>
  <li>如果是上面的原因1违反, 那么p[z]是黑色，不会进入循环，直接在最后一行把根节点设为黑色</li>
  <li>如果是原因2违反，情况就要复杂一些，不能简单地把当前节点或者其父节点设为黑色就能解决问题，
因为此时可能会导致从根到各个叶节点路径上黑节点数目不相等（经过z的个数多1）。在这种情况下，
就要想办法把性质4的不一致向根节点“传递”，因为如果这种不一致到了根节点，
直接把根节点设为红色就可以，而不会引起其他的问题, 代码中分了三种情况：
    <ol>
      <li>
        <p>如果是情况1，p[z]和z的叔叔都是红色，可以把p[z]和y(z的叔叔)都设为黑色，
 然后把p[p[z]]设为红色，这样就把这种红红的不一致向上传递了两层，
 这种不一致在向上传递的过程中会有三种情况：</p>

        <ol>
          <li>没有造成不一致， 因为虽然把newz = p[p[z]]设为了红色，但可能此时p[newz]也是黑色，没有违反性质4</li>
          <li>造成不一致然后遇到了情况1， 这时会把这种不一致继续向上传递</li>
          <li>造成不一致然后遇到了情况2，3，这时直接可以通过旋转和颜色调整解决，不用向上传递</li>
        </ol>
      </li>
    </ol>

    <p>无论是哪一种情况，要么会被解决，要么传递到根由根来解决。</p>

    <ol>
      <li>如果是情况2，3，这时可以通过旋转和重新着色解决性质4的不一致，而不会造成其他问题。</li>
    </ol>
  </li>
</ol>

<h4 id="section-8">删除</h4>
<p>在删除一个节点时，如果被删除的节点是红色，
那么不会有问题，因为它的儿子和父亲都是黑色，
不会违背性质4，
同时任何路径上的黑色节点的个数也不会发生变化。
但如果删除的是一个黑色的节点y，会有以下原因导致性质违背：</p>

<ol>
  <li>如果y是根节点，而y的红色儿子成为了新的根，会违背性质2</li>
  <li>如果y的儿子x(y最多有一个儿子，可以从二叉查找树的删除中得到这个结论)和父亲都是红色，
那么会违背性质4</li>
  <li>删除y会导致经过y的路径上的黑节点数目个数少1，违背性质5</li>
</ol>

<p>函数RB-DELETE-FIXUP()用于在删除节点x的父亲时性质维护：</p>

<pre><code>def RB-DELETE-FIXUP(T, x):
    while x != root[T] and color[x] = BLACK
        do if x = left[p[x]]
            then w ← right[p[x]]
            if color[w] = RED
                then color[w] ← BLACK                                  ###case1
                color[p[x]] ← RED                                      ###case1
                LEFT-ROTATE (T, p[x])                                  ###case1
                w ← right[p[x]]                                        ###case1
            if color[left[w]] = BLACK and color[right[w]] = BLACK
                then color[w] ← RED                                    ###case2
                x ← p[x]                                               ###case2
            else if color[right[w]] = BLACK
                    then color[left[w]] ← BLACK                        ###case3
                    color[w] ← RED                                     ###case3
                    RIGHT-ROTATE (T, w)                                ###case3
                    w ← right[p[x]]                                    ###case3
                color[w] ← color[p[x]]                                 ###case4
                color[p[x]] ← BLACK                                    ###case4
                color[right[w]] ← BLACK                                ###case4
                LEFT-ROTATE (T, p[x])                                  ###case4
                x ← root[T]                                            ###case4
        else (same as then clause with “right” and “left” exchanged)
    color[x] ← BLACK
</code></pre>

<p>从代码中可以看出，原因1或者原因2都没有进入循环，直接通过把x设为黑色就能解决问题。
解决原因3的基本思路是给x赋予一层多余的黑色(充当一个黑色节点的计数)，试着把这个多余的黑色往根传递, 
在向上传递的过程中，可能会遇到3种情况：</p>

<ol>
  <li>这种多余的黑色传递到了一个红色的节点，那么直接把这个红色的节点设为黑色即可</li>
  <li>在传递过程中遇到了情况3，4，可以通过旋转和颜色调整而解决问题，不会引起其他的问题</li>
  <li>一直遇到情况2而传递到了根节点，这时直接去掉这个多余的黑色即可，
因为此时从根到叶节点的所有路径的黑节点数目都少1，性质5得到解决。</li>
</ol>

<p>为什么再调整过程中旋转的次数不超过3次？简单看来，有如下转换关系：</p>

<ol>
  <li>case1 -&gt; case2, case3, case4,情况1结束之后将到达情况2，或情况3，或情况4</li>
  <li>case2 -&gt; new while, 情况2之后将进入新的循环</li>
  <li>case3 -&gt; case4，情况3将到达情况4</li>
  <li>case4 -&gt; 终止，情况4之后把x设为root，将导致循环终止</li>
</ol>

<p>情况1会有旋转，如果进入了情况3或情况4，将导致循环终止，此时旋转次数不超过3次，
但如果进入进入情况2，那么将会进入新的循环，此时有可能碰到情况1然后再次旋转，
然后进入再进入情况2&#8230;这样一直向上到根，旋转的次数可能会超过3次，
是这样吗？</p>

<p>上面的情况的是不可能发生的，因为情况1会把p[x]设为红色，如果此时进入情况2，
在新的循环开始时，新的x就是p[x]，它的颜色是红色，直接会退出循环，把x设为黑色，
调整结束，不会再继续向上传递。所以旋转的次数不会超过3次。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[算法导论8~9章读书笔记]]></title>
    <link href="/clrs/2012/12/01/clrs-8-9"/>
    <updated>2012-12-01T00:00:00+08:00</updated>
    <id>/clrs/2012/12/01/clrs-8-9</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p></p>

<h3 id="section">比较排序的时间下界</h3>
<p>合并排序和堆排序在最坏情况下能够在O(nlgn)时间内排序n个数，
而快速排序则能够在平均情况下达到这个上界。
这些算法在确定元素的次序时，
都是基于元素间的比较。
这类排序算法称为<strong>比较排序</strong>。</p>

<p>比较排序的时间下界是O(nlgn)，
这意味着所有的基于比较的排序算法，在最坏情况下都要用<script type="math/tex"> \Omega (n \lg n) </script>
次比较来完成排序。</p>

<p>这是因为比较排序可以被抽象为<strong>决策树</strong>，
决策树是一棵满二叉数，
它的每一条从根节点到叶节点的路径都对应于比较排序的一次执行过程，
达到叶节点时，叶节点确定了这次排序的结果。
所以比较排序算法的最坏情况的比较次数等于决策树的高度。
n个数的排列总数有n!，每一种排列都必须在决策树的叶节点中出现，
高度为h的决策树的叶节点个数最多为<script type="math/tex"> 2^h </script>，故有：</p>

<script type="math/tex; mode=display">
n! \leq 2^h \\
\Longrightarrow   h \geq \lg (n!) = \Omega (n \lg n)
</script>

<p>所以比较排序的时间下界是O(nlgn)。</p>

<!--more-->

<h3 id="section-1">通过计数排序实现线性时间排序</h3>
<p>如果已经知道n个元素都是来自于0到k的整数，
其中<script type="math/tex"> k = O(n) </script>,
那么可以通过统计0到k中的每一个数在n个元素中出现的次数来达到排序的目的。
计数排序的运行时间为 <script type="math/tex"> \Theta (n) </script>。</p>

<p>书上在实现计数排序时，</p>

<ol>
  <li>首先遍历一遍原数组A，将各个元素出现次数统计到数组C中,此时C[0..k]的每一项C[i]表示i在A中的出现次数</li>
  <li>然后遍历一遍数组C, 使C[i]表示A中小于或等于i的元素个数</li>
  <li>最后遍历A(逆向遍历)，把结果放到数组B中，把A[i]放到B的C[A[i]]位置上，同时把C[A[i]]减1
(这是为了把重复的元素放到不同的位置上去)</li>
</ol>

<p>其实只需要让C[i]记录i在数组A中出现的次数，然后遍历一遍数组C就可以输出排序的结果。
具体遍历方法如下：</p>

<pre><code>j &lt;- 1
for i &lt;- 1 to k
    while C[i] &gt; 0
        do C[i] &lt;- C[i] - 1 
            A[j] = i
            j &lt;- j + 1
</code></pre>

<p>就能把排序好的结果保存到A中，不需要另外的数组B。
但是书上的这种方法有一个好处，它能保证排序是<strong>稳定</strong>的。
也就是说，具有相同值的元素在输出数组中的相对次序与输入数组中的相对次序一样。
因为是采取对A的逆向遍历，两个相同的元素中，位置靠前的元素后被遍历，此时C[i]已经变小了，
所以也会被放在更靠前的位置。稳定排序的好处在于它能够保证基数排序的正确性。</p>

<h3 id="section-2">基数排序：另一种线性时间排序</h3>
<p>基数排序主要解决的问题是对于多位整数的排序问题。
比如有n个d位数，每一位可以取k个不同的值，要对它进行排序，
一般的想法是先对最高位进行排序，
然后对于高位相同的子数组按次高位进行排序，依次类推。
这种想法的好处在于如果两个数中高位较大的数一定较大，
所以很容易把各个子数组的排序结果进行合并。比如排序10进制的三位数，
3XX一定都大于2XX，所以把2XX的子数组放在3XX的子数组前面就能保证合并结果的有序性。
但是它的不好的地方在于需要维护大量的子数组(随着递归的深度加深，子数组个数增多)，
这对于原始的基于纸带的排序的是不可行的。</p>

<p>那有没有一种排序方法，既能使后面的排序利用到前面排序的结果，
而且能够不需要维护大量的子数组呢？基数排序就是这样一种排序方法，
它先把数组按最低位进行排序，然后再对结果按次低位进行排序，依次类推。
每一次的排序都必须是<strong>稳定排序</strong>，这样能保证在按某位进行排序之后，
整个数组在从该位到最低位的子序列上都是有序的，可以通过一个简单的归纳加以证明。</p>

<p>同时，在对n个b位数进行排序时，每次可以按r位进行排序，
而不仅仅是1位，这样能够在<script type="math/tex"> \Omega ((b/r)(n + 2^r)) </script>的时间内完成对数组的排序。
可以选取适当的r达到最好的时间性能。</p>

<h3 id="section-3">同时找出数组中的最大值和最小值</h3>
<p>从一个数组中找出最大值或者最小值需要n-1次比较，
比如寻找最大值，首先将最大值设为第一个元素的值，
然后让n-1个元素和最大值进行比较，如果大于最大值，
就将最大值设为它，一共需要n-1次比较。</p>

<p>而如果是同时找出最大值和最小值呢，
当然可以分别按上面的方法找出最大值和最小值，
一共需要的比较次数是2n-2。</p>

<p>书上给出了另外一种方法：
成对的处理元素，将较小者与最小值相比，较大者与最大值相比，
这样能将比较次数降为<script type="math/tex">  3 \lceil n/2 \rceil </script>。</p>

<h3 id="i">在线性时间内选出数组中的第i小元素</h3>
<p>书上给出了两种方法：</p>

<p>第一种方法利用随机化快速排序算法中的RANDOMIZED-PARTITION函数对数组进行划分，然后根据
i是在哪一个部分中去相应部分中进行查找，这种方法能保证运行时间的期望是线性，代码如下：</p>

<pre><code>def RANDOMIZED-SELECT(A, p, r, i)
    q &lt;- RANDOMIZED-PARTITION(A, p, r)
    k &lt;- q - p + 1
    if i = k
        then return A[q]
    elseif i &lt; k
        then return RANDOMIZED-SELECT(A, p, q-1, i)
    else return RANDOMIZED-SELECT(A, q+1, r, i-k)
</code></pre>

<p>简单说明一下在划分的两个子数组中，如果有一个长度为0，
为什么不会它调用RANDOMIZED-SELECT:</p>

<ul>
  <li>如果子数组A[p..q-1]长度为0，则q = p，k = q - p + 1 = 1，<script type="math/tex"> i \geq k </script>, 不会对这个子数组调用RANDOMIZED-SELECT</li>
  <li>如果子数组A[q+1..r]长度为0，则q = r，k = r - p + 1 = length[A]，<script type="math/tex"> i \leq k </script>, 不会对这个子数组调用RANDOMIZED-SELECT</li>
</ul>

<p>第二种方法通过保证每次的划分是一个好的划分保证算法的线性时间。
具体的划分方式是：</p>

<ol>
  <li>将数组的n个元素划分为 <script type="math/tex"> \lceil n/5 \rceil </script>组，除最后一组之外，其余都有5个元素</li>
  <li>对每一组找到其中位数, 首先对每个数组进行插入排序，然后找到其中的中位数</li>
  <li>通过递归调用SELECT函数(就是找出数组中第i小元素的函数)，找到这些中位数中的中位数x</li>
  <li>以x作为划分元素对数组进行划分</li>
</ol>

<p>这个划分是一个好的划分，
因为能保证划分出来的两个子数组中任意一个的长度都不会超过某一个特定值。
在<script type="math/tex"> \lceil n/5 \rceil </script>个组中，
假设所有的中位数组成数组B[1..m]，其中 <script type="math/tex"> m = \lceil n/5 \rceil </script>,
假设x = B[k]，k = <script type="math/tex"> \lceil \frac{1}{2} \lceil \frac{n}{5} \rceil \rceil </script>,
在所有中位数在A[k..m]的组中，除去最后一组和x所在的组之外，其他的组至少有3个元素大于x，
所以大于x的元素个数至少为：</p>

<script type="math/tex; mode=display">
3(\lceil \frac{1}{2} \lceil \frac{n}{5} \rceil \rceil - 2) \geq \frac{3n}{10} - 6
</script>

<p>类似的小于x的元素个数至少有<script type="math/tex"> \frac{3n}{10} - 6 </script>个，
所以至多有<script type="math/tex"> \frac{7n}{10} + 6 </script>个元素被递归的调用SELECT，
有了这个结论之后就能保证SELECT函数可以在线性的时间内完成。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《算法导论》读书总结1]]></title>
    <link href="/clrs/2012/11/19/clrs-1"/>
    <updated>2012-11-19T00:00:00+08:00</updated>
    <id>/clrs/2012/11/19/clrs-1</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p></p>

<p>正如上一篇所说，我这几天都在学习《算法导论》这本书，
也终于是下定决心要好好把这本书看出个所以然来。
这几天看下来，发现最大的困扰并不是知识的难度，
而是克服自己内心的浮躁。因为这本书并不像其他的工科教材，
它讲得东西是比较偏理论一些，里面充满了各种数学公式，数学定理,
包括一个算法正确性的证明，都采取了形式化的证明手段，
力求证明的数学严格性。
如果只是需要粗粗理解各种算法是什么样的以及如何实现的话，
那么看这本书有点不太合适，
因为这方面的东西并不是这本书的重点。</p>

<p>而我，也是在粗粗了解了各种算法和实现的基础上学习这本书的，
一开始扫了一下书的第一章，第二章和第六章，
发现和其他的算法书还差不多嘛，
直到看到第七章快速排序，
看到作者在大概描述完快速排序算法之后
（这个快速排序的划分函数还和我以前见过的都不一样，更加容易理解和实现），
转而开始分析快速排序的性能和随机化版本，我才明白，
我不能再这么浮躁地只是抱着了解了解算法的目的来学习这本书了。
于是我又回过去仔仔细细地从头看到了第7章，
虽然说这本书里的定理和数学公式很多，但是并不难理解，
因为作者总是把每一个步骤解释地十分细致和透彻，
每一步的证明没有很大的跨越，
每一个结论的得出都会指明依据的定理或者是前面的结论。
所以说好好看下去其实并没有很大难度，
关键是要能够静得下心。</p>

<p>下面是1～7章中我的几点体会：</p>

<!--more-->

<h3 id="section">循环不变式</h3>
<p>循环不变式用于证明算法的正确性，
它能够保证一个算法能够终止，
而且当它终止时，得到的结果是正确的结果。
循环不变式的证明由三个部分组成：</p>

<ul>
  <li>初始化: 在循环的开始时，循环不变式成立。</li>
  <li>保持：如果在某一轮迭代之前循环不变式成立，那么在迭代之后，
循环不变式仍然成立。</li>
  <li>终止：如果保持循环不变式一直到循环的终止，那么这个算法将得到正确的结果。</li>
</ul>

<p>循环不变式与数学归纳法十分类似，采用的也是同样的思想。
在应用循环不变式对算法的正确性进行证明时，
难点不在于上述的三个步骤，而在于循环不变式的构造，
要构造一个循环不变式能够在循环过程中始终保持，
而且能体现算法正确性，这确实需要一定的技巧。
这就类似于在应用数学归纳法时选取归纳条件。</p>

<p>比如书中思考题2-2：（证明冒泡排序的正确性）</p>

<pre><code>for i &lt;- 1 to length[A]
    do for j &lt;- length[A] downto i+1
        do if A[j] &lt; A[j-1]
            then exchange A[j] &lt;-&gt; A[j-1]
</code></pre>

<p>b)对于2-4行(内层循环)给出一个循环不变式，并证明这个循环不变式是成立的。</p>

<p>内层循环的作用是把A[i]到A[n]（n是length[A]）中最小元素放到A[i],
可以采用如下的循环不变式来表示：</p>

<p>在每一轮迭代的开始，子数组A[j..n]中最小的元素位于A[j]。</p>

<p>下面对这个循环不变式进行证明：</p>

<ul>
  <li>初始化： 在第一轮迭代开始前，j = n，A[j..n]中就只有一个元素，
最小的元素位于A[n]。</li>
  <li>保持：在第k轮迭代时，
    <ul>
      <li>如果A[j] &gt;= A[j-1]，由循环不变式可知，
A[j]是字数组A[j..n]中最小的元素，那么循环结束时A[j-1]将是字数组A[j-1..n]中的最小元素。</li>
      <li>如果A[j] &lt; A[j-1], 那么在互换A[j]和A[j-1]之后，最小的元素仍然是A[j-1]。</li>
    </ul>
  </li>
  <li>终止: 在循环结束时j=i, 说明A[i]是字数组A[i..n]中的最小元素，
算法达到了把最小元素放到A[i]的目的。</li>
</ul>

<h3 id="section-1">渐进符号</h3>
<p>渐进符号用户描述一个算法的复杂度，以前只知道
渐进符号用于描述算法的量级，比如<script type="math/tex"> 2n^2 = O(n^2) </script> 
说明 
<script type="math/tex"> 2n^2 </script>
的量级是
<script type="math/tex">O(n^2)</script>。</p>

<p>书上给出了准确的定义:</p>

<script type="math/tex; mode=display">
O(g(n)) = \{f(n): \exists c,n， \forall n \geq n_0,  0 \leq f(n) \leq cg(n)\}
</script>

<p>同时有：</p>

<script type="math/tex; mode=display">
f(n) = O(g(n)) \Longleftrightarrow f(n) \in O(g(n)) 
</script>

<p>其他的符号如<script type="math/tex">\Omega</script>, <script type="math/tex">\Theta </script>都是类似的定义。
当然，我们只需要知道用<script type="math/tex"> O(f(n)) </script>来确定一个函数的上界，
用<script type="math/tex"> \Omega(f(n)) </script>来确定一个函数的下界就可以了。</p>

<h3 id="section-2">递归与主定理</h3>
<p>分治法是一种很常见的算法设计方法，
分治法的时间复杂度一般由如下的递归式给出：</p>

<script type="math/tex; mode=display">
T(n) = aT(n/b) + f(n)
</script>

<p>其中<script type="math/tex"> a \geq 1, b > 1</script>，f(n)一般用渐进函数表示。</p>

<p>对于这样的递归式，主定理给出了计算T(n)的方法：</p>

<ul>
  <li>如果存在常数<script type="math/tex"> \epsilon > 0 </script>，有
<script type="math/tex"> f(n) = O(n^{\log_ba - \epsilon}) </script>，
则
<script type="math/tex"> T(n) = \Theta(n^{\log_ba}) </script>;</li>
  <li>如果
<script type="math/tex"> f(n) = \Theta(n^{\log_ba}) </script>，
则
<script type="math/tex"> T(n) = \Theta(n^{\log_ba}\lg n) </script>;</li>
  <li>如果存在常数<script type="math/tex"> \epsilon > 0 </script>，有
<script type="math/tex"> f(n) = \Omega(n^{\log_ba + \epsilon}) </script>，
且对常数<script type="math/tex">% &lt;![CDATA[
 c < 1  %]]&gt;</script>与足够大的n,有
<script type="math/tex"> af(n/b) \leq cf(n) </script>，则
<script type="math/tex"> T(n) = \Theta(f(n)) </script>。</li>
</ul>

<p>运用主定理，能够很快地求出分治算法的复杂度。</p>

<h3 id="section-3">指示器随机变量</h3>
<p>指示器随机变量的定义如下:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
    X_H = I\{H\} = 
     \begin{cases}
         1 & \text{如果H发生} \\
         0 & \text{如果H没有发生}
     \end{cases}
 %]]&gt;</script>

<p>指示器随机变量是随机变量的一种，可以求出它的期望如下：
$$
    E[X_H] = Pr_H
$$</p>

<p>指示器随机变量有一个很好的性质，它只能取0或者1，
可以把它这些变量加起来求总的发生次数,
因此当它应用到重复随机试验中时,
统计重复试验某一事件发生次数的期望，
比如在随机化的快速排序中统计交换次数的期望,
可以通过如下公式得到：</p>

<script type="math/tex; mode=display"> 
E[X] = E[\sum_{i=1}^n X_i] = \sum_{i=1}^n E[X_i]
</script>

<p>要使等式的第二步成立，不一定要保证<script type="math/tex"> X_i </script>之间是相互独立的。</p>

<p>这周的读书笔记就先写到这里，下周开始写第8章开始的内容。</p>
]]></content>
  </entry>
  
</feed>